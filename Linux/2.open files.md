# open files 

## 1.起因
2019年7月23日 中午，11 点多，测试环境 3 台 kafka，同时因为错误而关闭进程

```
[2019-07-23 11:41:54,149] ERROR Error while accepting connection (kafka.network.Acceptor)
java.io.IOException: Too many open files
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:241)
	at kafka.network.Acceptor.accept(SocketServer.scala:323)
	at kafka.network.Acceptor.run(SocketServer.scala:268)
	at java.lang.Thread.run(Thread.java:745)
```

## 2.open files
### 2.1 检查 open files
>[root@CDHt-240-42 kafka_2.11-0.10.0.0]# ps -ef|grep kafka | grep kafka_2.11-0.10.0 |grep -v grep | lsof -p `awk '{print $2}'`|wc -l
7442

- 命令1
>lsof -p PId | wc -l
获取进程目前 open files

>[root@CDHt-240-44 kafka_2.11-0.10.0.0]# ps -ef|grep kafka | grep 
```
kafka_2.11-0.10.0|grep -v grep|ulimit -a `awk '{print $2}'`
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 127251
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 127251
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
```
```
[2019-07-23 23:02:24,343] ERROR Uncaught exception in scheduled task 'kafka-log-retention' (kafka.utils.KafkaScheduler)
java.io.IOException: Too many open files
```
>ulimit -n 10240

>ps -ef|grep kafka | grep kafka_2.11-0.10.0|grep -v grep|cat /proc/`awk '{print $2}'`/limits

>ulimit -s 10240

```
(kafka.server.ReplicaFetcherManager)
[2019-07-24 11:19:59,084] FATAL [ReplicaFetcherThread-0-1], Disk error while replicating data for [__consumer_offsets,22] (kafka.server.ReplicaFetcherThread)
kafka.common.KafkaStorageException: I/O exception in append to log '__consumer_offsets-22'
```
>>ulimit -f unlimited

ps -ef|grep kafka | grep kafka_2.11-0.10.0|grep -v grep|kill -9 `awk '{print $2}'`

rm -rf /data/kafka-logs/*

./bin/kafka-server-start.sh -daemon /data/.conf/server.properties

### 2.2 测试 open files
**测试代码**
```java
/**
 * @author XuZhuohao
 * @date 2019/7/24
 */
@RestController
@RequestMapping("open-files")
public class CreateFileController {
    private static List<OutputStream> inputStreamList = new ArrayList<>(16);
    @GetMapping("/{num}")
    public String create(@PathVariable int num) throws FileNotFoundException {
        while(num-- > 0){
            File file = new File("/data/" + System.currentTimeMillis() + num);
            OutputStream is = new FileOutputStream(file);
            inputStreamList.add(is);
        }
        return "success";
    }
}
```
- 启动测试程序
>[root@pf-zk data]# nohup java -jar open-files-0.0.1-SNAPSHOT.jar &


- 检查测试程序当前的参数
>[root@pf-zk data]# ps -ef|grep open-files-0.0.1-SNAPSHOT.jar | grep -v grep|cat /proc/`awk '{print $2}'`/limits
```
Limit                     Soft Limit           Hard Limit           Units     
Max cpu time              unlimited            unlimited            seconds   
Max file size             unlimited            unlimited            bytes     
Max data size             unlimited            unlimited            bytes     
Max stack size            8388608              unlimited            bytes     
Max core file size        0                    unlimited            bytes     
Max resident set          unlimited            unlimited            bytes     
Max processes             61928                61928                processes 
Max open files            4096                 4096                 files     
Max locked memory         65536                65536                bytes     
Max address space         unlimited            unlimited            bytes     
Max file locks            unlimited            unlimited            locks     
Max pending signals       61928                61928                signals   
Max msgqueue size         819200               819200               bytes     
Max nice priority         0                    0                    
Max realtime priority     0                    0                    
Max realtime timeout      unlimited            unlimited            us 
```
画重点
**Max open files            4096                 4096                 files     **

>[root@pf-zk data]# ps -ef|grep open-files-0.0.1-SNAPSHOT.jar | grep -v grep|ulimit -a `awk '{print $2}'`
```
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 61928
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 61928
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
```
画重点
**open files                      (-n) 1024**

**目前open files**
>[root@pf-zk data]# ps -ef|grep open-files-0.0.1-SNAPSHOT.jar | grep -v grep|lsof -p `awk '{print $2}'` | wc -l
48

- 调用接口，创建并打开 20 个文件（http://192.168.242.89:8090/open-files/20） 再检查
>[root@pf-zk data]# ps -ef|grep open-files-0.0.1-SNAPSHOT.jar | grep -v grep|lsof -p `awk '{print $2}'` | wc -l
69
- 调用接口，创建并打开 3000 个文件（http://192.168.242.89:8090/open-files/3000） 再检查
>[root@pf-zk data]# ps -ef|grep open-files-0.0.1-SNAPSHOT.jar | grep -v grep|lsof -p `awk '{print $2}'` | wc -l
3069
- 调用接口，创建并打开 800 个文件（http://192.168.242.89:8090/open-files/800） 再检查
>[root@pf-zk data]# ps -ef|grep open-files-0.0.1-SNAPSHOT.jar | grep -v grep|lsof -p `awk '{print $2}'` | wc -l
3869

- 调用接口，创建并打开 150 个文件（http://192.168.242.89:8090/open-files/150） 再检查
>[root@pf-zk data]# ps -ef|grep open-files-0.0.1-SNAPSHOT.jar | grep -v grep|lsof -p `awk '{print $2}'` | wc -l
4021

- 调用接口，创建并打开 65 个文件（http://192.168.242.89:8090/open-files/65）再检查
>[root@pf-zk data]# ps -ef|grep open-files-0.0.1-SNAPSHOT.jar | grep -v grep|lsof -p `awk '{print $2}'` | wc -l
4084

- 调用接口，创建并打开 8 个文件（http://192.168.242.89:8090/open-files/8） 再检查
>[root@pf-zk data]# ps -ef|grep open-files-0.0.1-SNAPSHOT.jar | grep -v grep|lsof -p `awk '{print $2}'` | wc -l
4092

- 调用接口，创建并打开 2 个文件（http://192.168.242.89:8090/open-files/2） 再检查
>[root@pf-zk data]# ps -ef|grep open-files-0.0.1-SNAPSHOT.jar | grep -v grep|lsof -p `awk '{print $2}'` | wc -l
4096

- 调用接口，创建并打开 1 个文件（http://192.168.242.89:8090/open-files/1） 再检查
>[root@pf-zk data]# ps -ef|grep open-files-0.0.1-SNAPSHOT.jar | grep -v grep|lsof -p `awk '{print $2}'` | wc -l
4097

**已经超过 4096 但是没有异常**