

# redis base



## 1. 简介



## 2. 安装







## 3. 数据淘汰策略

通常地，再内存足够的情况下，使用**过期策略**对 key 的过期进行管理，而当内存使用达到限制时，会使用**内存淘汰** 进行管理



### 3.1 过期策略

参考： [redis expire](https://redis.io/commands/expire#how-redis-expires-keys)

**定期删除+惰性删除**

redis 在使用时，可以对一个 key 设置过期时间（**设置了过期时间的key，一般称为 volatile**）,到期之后怎么删除呢？使用 **定期删除+惰性删除**

```shell
EXPIRE <KEY> <TTL> : 将 key 的生存时间设置为 ttl 秒
PEXPIRE <KEY> <TTL> : 将 key 的生存时间设置为 ttl 毫秒
EXPIREAT <KEY> <timestamp> : 将 key 的过期时间设为 timestamp 所指定的秒数时间戳
PEXPIREAT <KEY> <timestamp> : 将 key 的过期时间设为 timestamp 所指定的毫秒数时间戳
TTL <KEY> : 返回剩余生存时间 ttl 秒
PTTL <KEY> : 返回剩余生存时间 pttl 毫秒
RERSIST <KEY> : 移除一个键的过期时间
```

> [Redis keys are expired in two ways: a passive way, and an active way](https://redis.io/commands/expire#how-redis-expires-keys)



#### 3.1.1 惰性删除（passive way）

> A key is passively expired simply when some client tries to access it, and the key is found to be timed out.

当客户端访问一个 key 时，会先检查是否存在过期时间？是否已经过期？如果过期则删除



#### 3.1.2 定期删除（active way）

如果只使用 `passive way` ，那么会导致有些过期后，不再被访问的 `key` 会一直留在内存空间。于是就有了 `定期删除` 的方式

- redis 每1会做10次以下操作
  1. 随机测试 20 个设置过期时间的 keys
  2. 删除所有被判断为过期的 key
  3. 如果超过 25% 个 key 是过期的，那么重复步骤1

> This means that at any given moment the maximum amount of keys already expired that are using memory is at max equal to max amount of write operations per second divided by 4.



### 3.2 内存淘汰

参考：[lru-cache](https://redis.io/topics/lru-cache)

#### 3.2.1 Maxmemory configuration directive

在 redis 配置中，通过使用 `maxmemory` 配置 redis 使用内存大小的现在，可以通过 启动前配置配置文件 **redis.conf**，或者 启动后执行命令 `CONFIG SET`  来进行设置

如果配置为 0，则在内存使用上没有限制（在 64 位系统上来讲是这样的，32位会有隐式限制为3GB）

当内存使用达到配置限制时，会根据策略的选择做不同的处理



#### 3.2.2 内存淘汰策略（Eviction policies）

使用  `maxmemory-policy` 配置，配置策略

- **noeviction**:当内存达到限制时，客户端提交会使内存超出限制的指令时，返回异常
- **allkeys-lru**: 通过尝试删除最近使用较少的key （LRU）来为新的数据腾出空间
- **volatile-lru**: 通过尝试删除最近使用较少的设置了过期时间的key （LRU）来为新的数据腾出空间
- **allkeys-random**: 通过随机删除 key 来为新的数据腾出空间
- **volatile-random**: 通过随机删除设置了过期时间的 key 来为新的数据腾出空间
- **volatile-ttl**: 优先删除具有过期时间且过期时间较短的 key



#### 3.2.3 内存回收线程如何工作

- 步骤如下：
  1. 客户端运行一个新命令，导致数据增加
  2. redis 检查内存使用，如果超过 maxmemory 限制，使用回收策略进行回收
  3. 一个新命令被执行，以此类推

所以内存会不停地在内存限制区，不停地超出限制和返回限制下。如果提交一个大的数据，在某些时候会造成内存使用明显超出限制。





### 3.3 LRU - Least Recently Used

#### 3.3.1 LRU 步骤

- **步骤：**
  1. 新数据直接插入到列表头部
  2. 缓存数据被命中，将数据移动到列表头部
  3. 缓存已满的时候，移除列表尾部数据。

- 画图：

  ![lru-step](https://raw.githubusercontent.com/XuZhuohao/picture/master/db/NoSql/Redis/redis.png)





#### 3.3.2 LRU - 数据结构

对于 LRU 的数据结构，需要做到的是，保存有序，移动节点，添加节点（头结点），删除节点（尾节点），一般用于缓存所以需要保证查找的算法复杂度足够低。一般常用 **双向链表 + Hash散列** 来作为 LRU 的数据结构（这个结构也是 java 集合中 LinkHashMap 数据结构的实现）

**简单实现**

```java
package com.yui.study.algorithms.base.dto;

import lombok.Data;
import lombok.experimental.Accessors;

import java.util.HashMap;
import java.util.Map;

/**
 * @author YUI_HTT
 * @date 2021/3/30
 */
public class LruCache<K, V> {
    private Entry<V> head, tail;
    int capacity;
    int size;
    private Map<K, Entry<V>> cache;

    @Data
    @Accessors(chain = true)
    public static class Entry<T> {
        private Entry<T> preNode;
        private Entry<T> nextNode;
        private T value;
    }

    public LruCache(int capacity) {
        this.capacity = capacity;
        this.size = 0;
        this.head = new Entry<>();
        this.tail = new Entry<>();
        this.head.nextNode = this.tail;
        this.tail.preNode = head;
        cache = new HashMap<>(capacity);
    }

    /**
     * 放入元素
     * @param key
     * @param value
     */
    public void put(K key, V value){
        Entry<V> newNode = this.cache.get(key);
        if (newNode != null){
            moveToHead(newNode);
            newNode.value = value;
            return;
        }
        if (size == capacity){
            removeTail(key);
        }
        newNode = new Entry<>();
        newNode.value = value;
        addNode(newNode);
        this.cache.put(key, newNode);
        size++;
    }
    public V get(K key){
        Entry<V> node = this.cache.get(key);
        if (node == null){
            return null;
        }
        moveToHead(node);
        return node.value;
    }

    public void moveToHead(Entry<V> node){
        deleteNode(node);
        addNode(node);
    }

    public void removeTail(K key){
        deleteNode(this.tail.preNode);
        this.cache.remove(key);
        size--;
    }


    public void addNode(Entry<V> node){
        this.head.nextNode.preNode = node;
        node.preNode = this.head;
        node.nextNode = this.head.nextNode;
        this.head.nextNode = node;
    }

    public void deleteNode(Entry<V> node){
        node.preNode.nextNode = node.nextNode;
        node.nextNode.preNode = node.preNode;
    }


    public void display() {
        Entry<V> currentNode = this.head.nextNode;
        if(currentNode == null) {
            return;
        }
        while (currentNode.nextNode != null) {
            System.out.print(currentNode.value + "\t");
            currentNode = currentNode.nextNode;
        }
        System.out.println("");
    }

    public static void main(String[] args) {
        LruCache<String, String> cache = new LruCache<>(5);
        cache.put("test1", "1");
        cache.put("test2", "2");
        cache.put("test3", "3");
        cache.put("test4", "4");
        cache.put("test5", "5");
        cache.display();
        System.out.println(cache.get("test3"));
        cache.display();
        System.out.println(cache.get("test5"));
        cache.display();
        cache.put("test6", "6");
        cache.display();
    }
}
```

**运行结果如下：**

```text
5	4	3	2	1	
3
3	5	4	2	1	
5
5	3	4	2	1	
6	5	3	4	2
```





#### 3.3.3 拓展1：LRU-K

#### 3.3.4 拓展2：2Q

#### 3.3.5 拓展3： LIRS



### 3.4 LFU



## 4. 扩容





