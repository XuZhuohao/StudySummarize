# kafka Base

## 1.基本使用

### 1.1 线上部署

#### 1.1.1 操作系统

- **I/O 模型的使用：**实际上 Kafka 客户端底层使用了 Java 的 selector，selector 在 Linux 上的实现机制是 epoll，而在 Windows 平台上的实现机制是 select。因此在这一点上将 Kafka 部署在 Linux 上是有优势的，因为能够获得更高效的 I/O 性能。
- **数据网络传输效率：**零拷贝（Zero Copy）技术，就是当数据在磁盘和网络进行传输时避免昂贵的内核态数据拷贝从而实现快速的数据传输。在 Linux 部署 Kafka 能够享受到零拷贝技术所带来的快速数据传输特性。
- **社区支持度：**社区目前对 Windows 平台上发现的 Kafka Bug 不做任何承诺



#### 1.1.2 磁盘

**SSD or HDD**： Kafka 大量使用磁盘不假，可它使用的方式多是顺序读写操作，一定程度上规避了机械磁盘最大的劣势，即随机读写操作慢。所以在**性能上SSD并没有太大的优势，价格上机械磁盘更有优势**

kafka自身提供冗余，**可以不使用 RAID**

> 常我们认为SSD的顺序写TPS大约是HDD的4倍



#### 1.1.3 磁盘容量

- 新增消息数
- 消息留存时间
- 平均消息大小
- 备份数
- 是否启用压缩



#### 1.1.4 带宽

*假设你公司的机房环境是千兆网络，即 1Gbps，现在你有个业务，其业务目标或 SLA 是在 1 小时内处理 1TB 的业务数据。那么问题来了，你到底需要多少台 Kafka 服务器来完成这个业务呢？*

- 带宽是 1Gbps，即每秒处理 1Gb 的数据
- 通常情况下你只能假设 Kafka 会用到 70% 的带宽资源，因为总要为其他应用或进程留一些资源，也就是说单台 Kafka 服务器最多也就能使用大约 700Mb 的带宽资源
- 通常要再额外预留出 2/3 的资源，即单台服务器使用带宽 700Mb / 3 ≈ 240Mbps。
- 每秒需要处理 2336Mb 的数据，除以 240，约等于 10 台服务器。
- 如果消息还需要额外复制两份，那么总的服务器台数还要乘以 3，即 30 台
- 

### 1.2 重要的集群参数配置

#### 1.2.1 Broker 端参数

**log.dirs：**指定了 Broker 需要使用的若干个文件目录路径。没有默认参数

**log.dir：**只能表示单个路径，它是补充上一个参数用的。

一般只设置 **log.dirs** 用逗号分隔的多个路径，比如/home/kafka1,/home/kafka2,/home/kafka3这样。最好保证这些目录挂载到不同的物理磁盘上。

- 提升读写性能：比起单块磁盘，多块物理磁盘同时读写数据有更高的吞吐量。
- 能够实现故障转移：即 Failover。Kafka 1.1 版本新引入的强大功能

----

**listeners：**学名叫监听器，其实就是告诉外部连接者要通过什么协议访问指定主机名和端口开放的 Kafka 服务。格式为：<协议名称，主机名，端口号>

**advertised.listeners：**和 listeners 相比多了个 advertised。Advertised 的含义表示宣称的、公布的，就是说这组监听器是 Broker 用于对外发布的。

**host.name/port：**不要为它们指定值，都是过期的参数了。

----

**auto.create.topics.enable**：是否允许自动创建 Topic。最好设置为 false，有管理员控制创建。

**unclean.leader.election.enable**：是否允许 Unclean Leader 选举。是否准许落后太多的副本参与选举。false 可能导致分区没有 leader，true 可能导致数据丢失。最好设置为 false，不同版本默认值不一样。

**auto.leader.rebalance.enable**：是否允许定期进行 Leader 选举。建议设置为 false。

----

**log.retention.{hours|minutes|ms}**：这是个“三兄弟”，都是控制一条消息数据被保存多长时间。从优先级上来说 ms 设置最高、minutes 次之、hours 最低。

**log.retention.bytes：**这是指定 Broker 为消息保存的总磁盘容量大小。

**message.max.bytes：**控制 Broker 能够接收的最大消息大小。默认1000012 太少了，还不到 1MB。



#### 1.2.2 topic 级别参数

**Topic 级别参数会覆盖全局 Broker 参数的值**，而每个 Topic 都能设置自己的参数值，这就是所谓的 Topic 级别参数。

**retention.ms：**规定了该 Topic 消息被保存的时长。默认是 7 天，即该 Topic 只保存最近 7 天的消息。一旦设置了这个值，它会覆盖掉 Broker 端的全局参数值。

**retention.bytes：**规定了要为该 Topic 预留多大的磁盘空间。和全局参数作用相似，这个值通常在多租户的 Kafka 集群中会有用武之地。当前默认值是 -1，表示可以无限使用磁盘空间。



**topic 参数设置：**

> **创建：**
>
> bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic transaction --partitions 1 --replication-factor 1 --config retention.ms=15552000000 --config max.message.bytes=5242880
>
> **修改：**
>
> bin/kafka-configs.sh --zookeeper localhost:2181 --entity-type topics --entity-name transaction --alter --add-config max.message.bytes=10485760



#### 1.2.3 JVM 参数

> 将你的 JVM 堆大小设置成 6GB 吧，这是目前业界比较公认的一个合理值。我见过很多人就是使用默认的 Heap Size 来跑 Kafka，说实话默认的 1GB 有点小，毕竟 Kafka Broker 在与客户端进行交互时会在 JVM 堆上创建大量的 ByteBuffer 实例，Heap Size 不能太小

- 如果 Broker 所在机器的 CPU 资源非常充裕，建议使用 CMS 收集器。启用方法是指定-XX:+UseCurrentMarkSweepGC。
- 否则，使用吞吐量收集器。开启方法是指定-XX:+UseParallelGC。

**怎么设置 kafka jvm 参数呢**

设置下面这两个环境变量即可：

- KAFKA_HEAP_OPTS：指定堆大小。
- KAFKA_JVM_PERFORMANCE_OPTS：指定 GC 参数。

> $> export KAFKA_HEAP_OPTS=--Xms6g  --Xmx6g
> $> export KAFKA_JVM_PERFORMANCE_OPTS= -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true
> $> bin/kafka-server-start.sh config/server.properties



#### 1.2.4 操作系统参数

- **文件描述符限制:** ulimit -n
- **文件系统类型:**据官网的测试报告，XFS 的性能要强于 ext4，所以生产环境最好还是使用 XFS
- **Swappiness**：将 swap 完全禁掉以防止 Kafka 进程使用 swap 空间。但一旦设置成 0，当物理内存耗尽时，操作系统会触发 OOM killer 这个组件，它会随机挑选一个进程然后 kill 掉，即根本不给用户任何的预警。可以设置接近 0 的值，如 1
- **提交时间**：Flush 落盘时间默认是 5 秒。一般情况下我们会认为这个时间太频繁了，可以适当地增加提交间隔来降低物理磁盘的写操作。



## 2. 客户端

### 2.1 生产者

#### 2.1.1 分区

**分区的作用就是提供负载均衡的能力**



#### 2.1.2 分区策略

**分区策略是决定生产者将消息发送到哪个分区的算法**

1. 显式地配置生产者端的参数partitioner.class
2. 实现org.apache.kafka.clients.producer.Partitioner接口
3. int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);



##### 2.1.2.1 轮询策略（Round-robin）

**轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们最常用的分区策略之一。**



##### 2.1.2.2 随机策略（Randomness）

**如果追求数据的均匀分布，还是使用轮询策略比较好。**事实上，随机策略是老版本生产者使用的分区策略，在新版本中已经改为轮询了。



##### 2.1.2.3 按消息键保序策略

Kafka 允许为每条消息定义消息键，简称为 Key。

一旦消息被定义了 Key，那么你就可以保证**同一个 Key 的所有消息都进入到相同的分区**里面，由于每个分区下的消息处理都是有顺序的，故这个策略被称为按消息键保序策略。

Kafka 默认分区策略实际上同时实现了两种策略：如果**指定了 Key，那么默认实现按消息键保序策略**；如果**没有指定 Key，则使用轮询策略**。



##### 2.1.2.4 其他分区策略

还有一种比较常见的，即所谓的**基于地理位置的分区策略**。当然这种策略一般只针对那些大规模的 Kafka 集群，特别是跨城市、跨国家甚至是跨大洲的集群。



#### 2.1.3 压缩算法

Kafka 的消息层次都分为两层：**消息集合（message set）**以及**消息（message）**。一个消息集合中包含若干条**日志项（record item）**，而日志项才是真正封装消息的地方。

**Producer 端压缩、Broker 端保持、Consumer 端解压缩。**



##### 2.1.3.1 V1版本和V2版本的区别

- 消息的公共部分抽取出来放到外层消息集合里面，这样就不用每条消息都保存这些信息了
- 在 V2 版本中，消息的 CRC 校验工作就被移到了消息集合这一层。
- V1是对每条消息进行压缩，V2 是对整个消息集合进行压缩



##### 2.1.3.2 何时压缩

**压缩可能发生在两个地方：生产者端和 Broker 端。**

生产者程序中配置 **compression.type** 参数即表示启用指定类型的压缩算法

**Borker 压缩的情况：**

- Broker 端指定了和 Producer 端不同的压缩算法
  - Broker 指定压缩算法且与 Producer 不一致（不指定默认使用 Producer 的压缩算法）
  - broker 先解压后使用自己的压缩算法进行压缩
- Broker 端发生了消息格式转换
  - 消息格式转换主要是为了兼容老版本的消费者程序（V1 和 V2 的转换）
  - 这种消息格式转换对性能是有很大影响的，除了这里的压缩之外，它还让 Kafka 丧失了引以为豪的 Zero Copy 特性。



##### 2.1.3.3 何时解压

- 通常来说解压缩发生在消费者程序中，，当消息到达 Consumer 端后，由 Consumer 自行解压缩还原成之前的消息。
- Kafka 会将启用了哪种压缩算法封装进消息集合中，这样消费者就能读取到压缩算法去进行解压
- Broker 端写入时都要发生解压缩操作，目的就是为了对消息执行各种验证。



##### 2.1.3.4 压缩算法对比

- 吞吐量方面：LZ4 > Snappy > zstd 和 GZIP；
- 压缩比方面，zstd > LZ4 > GZIP > Snappy
- 具体到物理资源，使用 Snappy 算法占用的网络带宽最多，zstd 最少
- 在 CPU 使用率方面，各个算法表现得差不多，只是在压缩时 Snappy 算法使用的 CPU 较多一些，而在解压缩时 GZIP 算法则可能使用更多的 CPU



##### 2.1.3.5 最佳实践

- 启用压缩的一个条件就是 Producer 程序运行机器上的 CPU 资源要很充足
- 带宽资源有限，建议开启压缩
  - CPU 资源有很多富余，强烈建议你开启 zstd 压缩



### 2.1.4 消息丢失
